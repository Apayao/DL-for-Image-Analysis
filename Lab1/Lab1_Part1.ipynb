{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7a705d20",
      "metadata": {
        "id": "7a705d20"
      },
      "source": [
        "# Lab1 â€” PyTorch Foundations for Computer Vision\n",
        "\n",
        "**Course**: Deep Learning for Image Analysis\n",
        "\n",
        "**Class**: M2 IASD App  \n",
        "\n",
        "**Professor**: Mehyar MLAWEH\n",
        "\n",
        "---\n",
        "\n",
        "## Objectives\n",
        "By the end of this lab, you should be able to:\n",
        "\n",
        "- Understand how **neurons and layers** are implemented in PyTorch\n",
        "- Manipulate **tensors** and reason about shapes\n",
        "- Use **autograd** to compute gradients\n",
        "- Implement a **training loop** yourself\n",
        "- Connect theory (neurons, loss, backprop) to actual code\n",
        "\n",
        "âš ï¸ This notebook is **intentionally incomplete**.  \n",
        "Whenever you see **`# TODO`**, you are expected to write code."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e07470cd",
      "metadata": {
        "id": "e07470cd"
      },
      "source": [
        "\n",
        "**Deadline:** ðŸ—“ï¸ **Saturday, February 7th (23:59)**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60119f3a",
      "metadata": {
        "id": "60119f3a"
      },
      "source": [
        "## ðŸ¤– A small (honest) note before you start\n",
        "\n",
        "Letâ€™s be real for a second.\n",
        "\n",
        " I know you **can use LLMs (ChatGPT, Copilot, Claude, etc.)** to help you with this lab.  \n",
        "And yes, **I use them too**, so donâ€™t worry ðŸ˜„\n",
        "\n",
        "ðŸ‘‰ **You are allowed to use AI tools.**  \n",
        "But hereâ€™s the deal:\n",
        "\n",
        "- Donâ€™t just **copyâ€“paste** code you donâ€™t understand  \n",
        "- Take time to **read, question, and modify** what the model gives you  \n",
        "- If you can solve a block **by yourself, without AI**, thatâ€™s excellent\n",
        "\n",
        "Remember:\n",
        "\n",
        "> AI can write code for you, but **only you can understand it** â€” and understanding is what matters for exams, projects, and real work.\n",
        "\n",
        "Use these tools **as assistants, not as replacements for thinking**.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“š Useful documentation (highly recommended)\n",
        "\n",
        "You will often find answers faster (and more reliably) by checking the official documentation:\n",
        "\n",
        "- **PyTorch main documentation**  \n",
        "  https://pytorch.org/docs/stable/index.html\n",
        "\n",
        "- **PyTorch tensors**  \n",
        "  https://pytorch.org/docs/stable/tensors.html\n",
        "\n",
        "- **Neural network modules (`torch.nn`)**  \n",
        "  https://pytorch.org/docs/stable/nn.html\n",
        "\n",
        "- **Loss functions** (`BCEWithLogitsLoss`, CrossEntropy, etc.)  \n",
        "  https://pytorch.org/docs/stable/nn.html#loss-functions\n",
        "\n",
        "- **Optimizers** (`SGD`, `Adam`, â€¦)  \n",
        "  https://pytorch.org/docs/stable/optim.html\n",
        "\n",
        "If you learn how to **navigate the documentation**, you are already thinking like a real AI engineer ðŸ‘Œ\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f278eff5",
      "metadata": {
        "id": "f278eff5"
      },
      "source": [
        "## PART I"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de614322",
      "metadata": {
        "id": "de614322"
      },
      "source": [
        "## 0) Colab setup â€” GPU check\n",
        "\n",
        "**Instructions**\n",
        "1. In Colab: `Runtime â†’ Change runtime type to GPU T4`\n",
        "2. Select **GPU** (T4 in Colab)\n",
        "3. Save and restart runtime\n",
        "\n",
        "Then run the cell below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "72e3ba23",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72e3ba23",
        "outputId": "686aeeeb-48c6-445a-d93e-93f275ed214e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.9.0+cu126\n",
            "CUDA available: True\n",
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "\n",
        "# TODO: set the device correctly (cuda if available, else cpu)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(\"Using device:\", device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fcc7ceb1",
      "metadata": {
        "id": "fcc7ceb1"
      },
      "source": [
        "## 1) Imports and reproducibility\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d0ce2798",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0ce2798",
        "outputId": "eda44574-e95d-4439-f1bf-0d8f59e9904c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7edd98285050>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# TODO: fix the random seed for reproducibility\n",
        "torch.manual_seed(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9349f5a5",
      "metadata": {
        "id": "9349f5a5"
      },
      "source": [
        "## 2) PyTorch tensors and shapes\n",
        "\n",
        "Tensors are multi-dimensional arrays that support:\n",
        "- GPU acceleration\n",
        "- automatic differentiation\n",
        "\n",
        "Understanding **shapes** is critical in deep learning.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d2998b3f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2998b3f",
        "outputId": "5980995b-0e7f-4ef7-cac1-c5d683e8ac94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a shape: torch.Size([3])\n",
            "b shape: torch.Size([4, 5])\n"
          ]
        }
      ],
      "source": [
        "# Examples\n",
        "a = torch.tensor([1.0, 2.0, 3.0])\n",
        "b = torch.randn(4, 5)\n",
        "\n",
        "print(\"a shape:\", a.shape)\n",
        "print(\"b shape:\", b.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d675977",
      "metadata": {
        "id": "0d675977"
      },
      "source": [
        "### ðŸ” Question (answer inside the markdown)\n",
        "- How many dimensions does tensor `b` have?\n",
        "\n",
        "b is a tensor of dimension 2.\n",
        "\n",
        "\n",
        "\n",
        "- What does each dimension represent conceptually?\n",
        "When working with tensors of size 2, usually the first dimension represents the size of the dataset, the second one is the number of features for each observation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ea0588f",
      "metadata": {
        "id": "9ea0588f"
      },
      "source": [
        "### âœ…Tensor operations\n",
        "\n",
        "Complete the following:\n",
        "\n",
        "1. Create a tensor `x` of shape `(8, 3)` with random values  \n",
        "2. Compute:\n",
        "   - the **mean of each column**\n",
        "   - the **L2 norm of each row**\n",
        "3. Normalize `x` **row-wise** using the L2 norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b4629e99",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4629e99",
        "outputId": "003d70b2-c57c-4814-e1fa-2f990a9b1214"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 3]) torch.Size([3]) torch.Size([8]) torch.Size([8, 3])\n",
            "tensor([[ 0.3189, -0.4245,  0.3057],\n",
            "        [-0.7746,  0.0349,  0.3211],\n",
            "        [ 1.5736, -0.8455,  0.3672],\n",
            "        [ 0.1754,  1.3852, -0.4459],\n",
            "        [ 1.4451,  0.8564,  2.2181],\n",
            "        [ 0.5232,  1.1754,  0.5612],\n",
            "        [-0.4527, -0.7718, -0.1722],\n",
            "        [ 0.5238,  0.0566,  0.4263]]) tensor([[ 0.5205, -0.6929,  0.4990],\n",
            "        [-0.9230,  0.0416,  0.3826],\n",
            "        [ 0.8629, -0.4636,  0.2014],\n",
            "        [ 0.1197,  0.9451, -0.3042],\n",
            "        [ 0.5194,  0.3078,  0.7972],\n",
            "        [ 0.3727,  0.8374,  0.3998],\n",
            "        [-0.4969, -0.8470, -0.1890],\n",
            "        [ 0.7729,  0.0835,  0.6290]])\n",
            "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n"
          ]
        }
      ],
      "source": [
        "# TODO: create x\n",
        "x = torch.randn(8, 3)\n",
        "\n",
        "# TODO: column mean\n",
        "col_mean = torch.mean(x, dim=0)\n",
        "\n",
        "# TODO: row-wise L2 norm\n",
        "row_norm = torch.norm(x, p=2, dim=1)\n",
        "\n",
        "# TODO: normalized tensor\n",
        "x_normalized = x / row_norm.view(-1, 1)\n",
        "\n",
        "print(x.shape, col_mean.shape, row_norm.shape, x_normalized.shape)\n",
        "\n",
        "print(x, x_normalized)\n",
        "print(torch.norm(x_normalized, p=2, dim=1))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d0f8928",
      "metadata": {
        "id": "4d0f8928"
      },
      "source": [
        "## 3) Artificial neuron â€” from math to code\n",
        "\n",
        "A neuron computes:\n",
        "\n",
        "$$\n",
        "z = \\sum_i w_i x_i + b\n",
        "$$\n",
        "\n",
        "Then applies an activation function:\n",
        "\n",
        "$$\n",
        "y = g(z)\n",
        "$$\n",
        "\n",
        "This section connects directly to the theory seen in class.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6d271c97",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d271c97",
        "outputId": "9dcc78dd-689b-4612-dc9c-a573d2c1cf66"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-0.8000)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "x = torch.tensor([1.0, -2.0, 3.0])\n",
        "w = torch.tensor([0.2, 0.4, -0.1])\n",
        "b = torch.tensor(0.1)\n",
        "\n",
        "z = torch.sum(x * w) + b\n",
        "z\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db2d7490",
      "metadata": {
        "id": "db2d7490"
      },
      "source": [
        "### Activation functions\n",
        "\n",
        "1. Implement **ReLU**\n",
        "2. Implement **Sigmoid**\n",
        "3. Apply both to `z` and compare the outputs\n",
        "\n",
        "Which activation preserves negative values?\n",
        "\n",
        "None of them preserves negative values. ReLU kills negative signals by setting them to 0. Sigmoid converts real values to probabilities, so to a value between 0 and 1.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f307df40",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f307df40",
        "outputId": "0ec22bd1-3890-4fc8-d912-2cea5d700736"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.), tensor(0.3100))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# TODO\n",
        "def relu(z):\n",
        "  return torch.max(z, torch.zeros_like(z))\n",
        "\n",
        "def sigmoid(z):\n",
        "  return 1/(1+torch.exp(-z))\n",
        "\n",
        "y_relu = relu(z)\n",
        "y_sigmoid = sigmoid(z)\n",
        "y_relu, y_sigmoid\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e764019",
      "metadata": {
        "id": "8e764019"
      },
      "source": [
        "## 4) Autograd and gradients\n",
        "\n",
        "PyTorch uses **automatic differentiation** to compute gradients\n",
        "using the **chain rule** (backpropagation).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "50f1aab4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50f1aab4",
        "outputId": "ef340d92-ffd7-43af-8ebd-9a1562297364"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 2.890000104904175\n",
            "grad w: tensor([-3.4000, -6.8000,  3.4000])\n",
            "grad b: tensor(-3.4000)\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([1.0, 2.0, -1.0], requires_grad=True)\n",
        "w = torch.tensor([0.5, -0.3, 0.8], requires_grad=True)\n",
        "b = torch.tensor(0.2, requires_grad=True)\n",
        "\n",
        "z = torch.sum(x * w) + b\n",
        "loss = (z - 1.0) ** 2\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "print(\"loss:\", loss.item())\n",
        "print(\"grad w:\", w.grad)\n",
        "print(\"grad b:\", b.grad)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe2c78a9",
      "metadata": {
        "id": "fe2c78a9"
      },
      "source": [
        "### ðŸ” Conceptual question\n",
        "\n",
        "- If `b.grad > 0`, should `b` increase or decrease after a gradient descent step?\n",
        "Explain **why** in one sentence.\n",
        "\n",
        "The gradient indicates the direction of the steepest ascent. Our goal is to minimise the loss, so we take steps into the opposite direction of the gradient. Therefore, after one step of gradient DESCENT, the value of should decrease.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5bdee3e",
      "metadata": {
        "id": "b5bdee3e"
      },
      "source": [
        "## 5) Toy classification dataset\n",
        "\n",
        "We create a **linearly separable** dataset.\n",
        "\n",
        "Label rule:\n",
        "- class = 1 if `xâ‚ + xâ‚‚ + xâ‚ƒ > 0`\n",
        "- else class = 0\n",
        "\n",
        "This mimics a very simple classification problem.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15c8bc6a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15c8bc6a",
        "outputId": "73939ba2-d0a9-416e-cfa4-d84ee1e2101b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([400, 3]) torch.Size([400, 1])\n",
            "torch.Size([100, 3]) torch.Size([100, 1])\n"
          ]
        }
      ],
      "source": [
        "# TODO: generate a dataset of size N=500 with 3 features\n",
        "X = torch.randn(500, 3)\n",
        "y = (torch.sum(X, dim=1) > 0).float().view(-1,1) # shape (N, 1)\n",
        "\n",
        "# TODO: split into train (80%) and validation (20%)\n",
        "train_size = 0.8*X.shape[0]\n",
        "X_train = X[:int(train_size),:]\n",
        "y_train = y[:int(train_size)]\n",
        "\n",
        "X_val = X[int(train_size):,:]\n",
        "y_val = y[int(train_size):]\n",
        "\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_val.shape, y_val.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79c16fc2",
      "metadata": {
        "id": "79c16fc2"
      },
      "source": [
        "## 6) Model definition\n",
        "\n",
        "We define a small **MLP** (fully-connected network):\n",
        "\n",
        "`3 â†’ 16 â†’ 8 â†’ 1`\n",
        "\n",
        "Activation: ReLU  \n",
        "Output: raw logits (no sigmoid)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7b69f8d",
      "metadata": {
        "id": "d7b69f8d"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            # TODO: Linear 3 â†’ 16\n",
        "            nn.Linear(3, 16),\n",
        "            # TODO: ReLU\n",
        "            nn.ReLU(),\n",
        "            # TODO: Linear 16 â†’ 8\n",
        "            nn.Linear(16, 8),\n",
        "            # TODO: ReLU\n",
        "            nn.ReLU(),\n",
        "            # TODO: Linear 8 â†’ 1\n",
        "            nn.Linear(8, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# TODO: create model and move it to the GPU\n",
        "model = MLP().to(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c13b2d2",
      "metadata": {
        "id": "9c13b2d2"
      },
      "source": [
        "###  parameters\n",
        "\n",
        "1. Compute **by hand** the total number of parameters\n",
        "According to https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html, the bias term is included by default, in which case the number of parameters is:\n",
        "- 3*16 + 16 biases for the first layer, which adds up to 64\n",
        "- 16*8 which is 128, plus the 8 biases which is 136\n",
        "- 8 weights + 1 bias for the output layer, which is 9.\n",
        "\n",
        "\n",
        "In total, we thus have 209 parameters.\n",
        "\n",
        "2. Verify your answer using PyTorch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6168e4a5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6168e4a5",
        "outputId": "f039d6a9-7ab9-4801-bf9e-41ee57011bd5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "209"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# TODO: count parameters with PyTorch\n",
        "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "total_params\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19f204fb",
      "metadata": {
        "id": "19f204fb"
      },
      "source": [
        "## 7) Training loop\n",
        "\n",
        "You must complete the full training loop:\n",
        "- forward pass\n",
        "- loss computation\n",
        "- backward pass\n",
        "- optimizer step\n",
        "\n",
        "Loss: `BCEWithLogitsLoss`\n",
        "Optimizer: `SGD`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d80ad2c9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d80ad2c9",
        "outputId": "94b788a6-b7a5-49ae-b864-3259d2e73191"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 | loss = 0.7348411679267883\n",
            "Epoch 10 | loss = 0.7142819166183472\n",
            "Epoch 15 | loss = 0.6984398365020752\n",
            "Epoch 20 | loss = 0.683353841304779\n",
            "Epoch 25 | loss = 0.6668954491615295\n",
            "Epoch 30 | loss = 0.6465408802032471\n",
            "Epoch 35 | loss = 0.6211355328559875\n",
            "Epoch 40 | loss = 0.5896747708320618\n",
            "Epoch 45 | loss = 0.5514328479766846\n",
            "Epoch 50 | loss = 0.5064075589179993\n",
            "Epoch 55 | loss = 0.4565713107585907\n",
            "Epoch 60 | loss = 0.40497106313705444\n",
            "Epoch 65 | loss = 0.3549319803714752\n",
            "Epoch 70 | loss = 0.3094232380390167\n",
            "Epoch 75 | loss = 0.2699418067932129\n",
            "Epoch 80 | loss = 0.2367388904094696\n",
            "Epoch 85 | loss = 0.20942749083042145\n",
            "Epoch 90 | loss = 0.18705607950687408\n",
            "Epoch 95 | loss = 0.16866859793663025\n",
            "Epoch 100 | loss = 0.15352974832057953\n",
            "Epoch 105 | loss = 0.14105993509292603\n",
            "Epoch 110 | loss = 0.1306404024362564\n",
            "Epoch 115 | loss = 0.12180926650762558\n",
            "Epoch 120 | loss = 0.1142706647515297\n",
            "Epoch 125 | loss = 0.10777018219232559\n",
            "Epoch 130 | loss = 0.10210128873586655\n",
            "Epoch 135 | loss = 0.09711051732301712\n",
            "Epoch 140 | loss = 0.09265542775392532\n",
            "Epoch 145 | loss = 0.08866497129201889\n",
            "Epoch 150 | loss = 0.08507504314184189\n",
            "Epoch 155 | loss = 0.08182773739099503\n",
            "Epoch 160 | loss = 0.07886670529842377\n",
            "Epoch 165 | loss = 0.07615824788808823\n",
            "Epoch 170 | loss = 0.0736742839217186\n",
            "Epoch 175 | loss = 0.07138459384441376\n",
            "Epoch 180 | loss = 0.06926009058952332\n",
            "Epoch 185 | loss = 0.06727904081344604\n",
            "Epoch 190 | loss = 0.06544025987386703\n",
            "Epoch 195 | loss = 0.06372254341840744\n",
            "Epoch 200 | loss = 0.06210804358124733\n"
          ]
        }
      ],
      "source": [
        "# TODO: move data to device\n",
        "X_train_d = X_train.to(device)\n",
        "y_train_d = y_train.to(device)\n",
        "X_val_d = X_val.to(device)\n",
        "y_val_d = y_val.to(device)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "for epoch in range(1,201):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # TODO: forward\n",
        "    logits = model(X_train_d)\n",
        "\n",
        "    # TODO: loss\n",
        "    loss = criterion(logits, y_train_d)\n",
        "\n",
        "    # TODO: backward\n",
        "    loss.backward()\n",
        "\n",
        "    # TODO: update\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 5 == 0:\n",
        "        print(\"Epoch\", epoch, \"| loss =\", float(loss))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c894744",
      "metadata": {
        "id": "5c894744"
      },
      "source": [
        "## 8) Evaluation\n",
        "\n",
        "1. Apply `sigmoid` to the logits\n",
        "2. Convert probabilities to predictions\n",
        "3. Compute **accuracy** on the validation set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b10b706c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b10b706c",
        "outputId": "aa037a3c-5d59-40a0-861d-ec6a7e499bcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100, 1]) torch.Size([100, 1])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9900, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# TODO: evaluation\n",
        "with torch.no_grad():\n",
        "  logits = model(X_val_d)\n",
        "  probits = torch.sigmoid(logits)\n",
        "  preds =  (probits > .5).float()\n",
        "\n",
        "print(preds.shape, y_val_d.shape)\n",
        "\n",
        "accuracy = (preds == y_val_d).float().mean()\n",
        "accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9698541c",
      "metadata": {
        "id": "9698541c"
      },
      "source": [
        "## 9) Reflection questions (answer inside the markdown)\n",
        "\n",
        "1. Why do we **not** apply sigmoid inside the model?\n",
        "The loss function we're using in the network is BCEWithLogitsLoss. According to the doc (https://docs.pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html), this function combines Sigmoid and and BCE Loss in one layer.\n",
        "2. What would happen if we removed all ReLU activations?\n",
        "If we were to remove ReLU activations, there would not be any non-linearity at all. The network would only become equivalent to several matrix multiplications applied in a row.\n",
        "3. How does this toy problem relate to image classification?\n",
        "The principle is pretty much the same. Instead of a tensor of size n\\*1, we have a tensor with 28\\*28 entries. The network learns weights by extracting features in our dataset, in order to minimise the loss and correctly classify the inputs.\n",
        "\n",
        "Write short answers (2â€“3 lines each).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be9f2ed3",
      "metadata": {
        "id": "be9f2ed3"
      },
      "source": [
        "## 10) Bridge to Computer Vision\n",
        "\n",
        "So far:\n",
        "- inputs = vectors of size 3\n",
        "- layers = fully-connected\n",
        "\n",
        "Next session:\n",
        "- inputs = images `(B, C, H, W)`\n",
        "- layers = convolutions\n",
        "- same training logic\n",
        "\n",
        "ðŸ‘‰ **Architecture changes, learning principles stay the same.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f479aad6",
      "metadata": {
        "id": "f479aad6"
      },
      "source": [
        "## Part II â€” Training on MNIST\n",
        "\n",
        "Check the next notebook"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}